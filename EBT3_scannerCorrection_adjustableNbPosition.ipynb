{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\": \"kLr4fYcqcSpbuI95brIH3vnnYCquzzSxHPU6XGQCIkQRGJwhg0StNbj1eegrHs12\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\": \"xIGPmVtaOm+z0BqfSOMn4lOR6ciex448GIKG4eE61LsAvmGj48XcMQZtKcE/UXZe\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\": \"Dc9u1wF/0zApGIWoBbH77iWEHtdmkuYWG839Uzmv8y8yBLXebjO9ZnERsde5Ln/P\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\": \"cT9JaBz7GiRXdENrJLZNSC6eMNF3nh3fa5fTF51Svp+ukxPdwcU5kGXGPBgDCa2j\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.1.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LIBRARIES #\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.interpolate import CubicSpline, interp1d\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import LinearColorMapper, BasicTicker, ColorBar, Plot, CustomJS, ColumnDataSource, Rect\n",
    "from bokeh.layouts import row, gridplot, column\n",
    "from bokeh.models.widgets import Slider, Button\n",
    "from bokeh.events import ButtonClick\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from Gafchromic import Radiochromic_RB\n",
    "from Gafchromic_multichannel import Radiochromic_multilinear\n",
    "\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0,
     31,
     48,
     66,
     119,
     140,
     169,
     222
    ]
   },
   "outputs": [],
   "source": [
    "# FONCTIONS:\n",
    "\n",
    "\n",
    "# Colors to be used in multiple lines graphs\n",
    "colors = ['aqua', 'aquamarine', 'azure', 'bisque', 'black', 'blue', 'blueviolet', 'brown', 'burlywood', \n",
    "          'cadetblue', 'chartreuse', 'chocolate', 'coral', 'cornflowerblue', 'cornsilk', 'crimson', 'cyan',\n",
    "           'darkblue', 'darkcyan', 'darkgoldenrod', 'darkgray', 'darkgreen', 'darkgrey', 'darkkhaki', 'darkmagenta', \n",
    "          'darkolivegreen', 'darkorange', 'darkorchid', 'darkred', 'darksalmon', 'darkseagreen', 'darkslateblue', \n",
    "          'darkslategray', 'darkslategrey', 'darkturquoise', 'darkviolet', 'deeppink', \n",
    "          'deepskyblue', 'dimgray', 'dimgrey', 'dodgerblue', 'firebrick', 'floralwhite', 'forestgreen', 'fuchsia', \n",
    "          'gainsboro', 'ghostwhite', 'gold', 'goldenrod', 'gray', 'green', 'greenyellow', 'grey', 'honeydew', 'hotpink', \n",
    "          'indianred', 'indigo', 'ivory', 'khaki', 'lavender', 'lavenderblush', 'lawngreen', 'lemonchiffon', 'lightblue', \n",
    "          'lightcoral', 'lightcyan', 'lightgoldenrodyellow', 'lightgray', 'lightgreen', 'lightgrey', 'lightpink', \n",
    "          'lightsalmon', 'lightseagreen', 'lightskyblue', 'lightslategray', 'lightslategrey', 'lightsteelblue', \n",
    "          'lightyellow', 'lime', 'limegreen', 'linen', 'magenta', 'maroon', 'mediumaquamarine', 'mediumblue', \n",
    "          'mediumorchid', 'mediumpurple', 'mediumseagreen', 'mediumslateblue', 'mediumspringgreen', 'mediumturquoise', \n",
    "          'mediumvioletred', 'midnightblue', 'mintcream', 'mistyrose', 'moccasin', 'navajowhite', 'navy', 'oldlace', \n",
    "          'olive', 'olivedrab', 'orange', 'orangered', 'orchid', 'palegoldenrod', 'palegreen', 'paleturquoise', \n",
    "          'palevioletred', 'papayawhip', 'peachpuff', 'peru', 'pink', 'plum', 'powderblue', 'purple', 'red', 'rosybrown', \n",
    "          'royalblue', 'saddlebrown', 'salmon', 'sandybrown', 'seagreen', 'seashell', 'sienna', 'silver', 'skyblue', \n",
    "          'slateblue', 'slategray', 'slategrey', 'snow', 'springgreen', 'steelblue', 'tan', 'teal', 'thistle', 'tomato', \n",
    "          'turquoise', 'violet', 'wheat']\n",
    "\n",
    "\n",
    "\n",
    "# subsample data array : #\n",
    "# @params:\n",
    "#  array : array to subsample\n",
    "#  sizex : size in x\n",
    "#  sizey : size in y\n",
    "#  subfactor :  subsampling factor\n",
    "def subSampleDataArray(array, subfactor):\n",
    "    newsizex = int(array.shape[1]/subfactor)\n",
    "    newsizey = int(array.shape[0]/subfactor)\n",
    "\n",
    "    newarray = array[0:newsizey*subfactor, 0:newsizex*subfactor]\\\n",
    "                        .reshape((newsizey, subfactor, newsizex, subfactor)).mean(3).mean(1)\n",
    "    \n",
    "    return newarray\n",
    "\n",
    "\n",
    "\n",
    "# subsample data array : #\n",
    "# @params:\n",
    "#  array : array to subsample\n",
    "#  sizex : size in x\n",
    "#  sizey : size in y\n",
    "#  subfactor :  subsampling factor\n",
    "def subSampleRGBArray(array, subfactor):\n",
    "    newsizex = int(array.shape[1]/subfactor)\n",
    "    newsizey = int(array.shape[0]/subfactor)\n",
    "\n",
    "    newarray = array[0:newsizey*subfactor, 0:newsizex*subfactor,:]\\\n",
    "                        .reshape((newsizey, subfactor, newsizex, subfactor, 3)).mean(3).mean(1)\n",
    "    \n",
    "    return newarray\n",
    "\n",
    "\n",
    "\n",
    "# Displays two images and profiles\n",
    "#   \n",
    "# @params:\n",
    "#  img1: image array 1\n",
    "#  img2: image array 2\n",
    "#  col: column nb for the profile\n",
    "#  line: line nb for the profile\n",
    "def compare2Imgs(img1, img2, col, line, plotwidth=450, title1='dose image 1', title2='dose image 2',\n",
    "                colorprofile1='firebrick', colorprofile2='darkblue'): \n",
    "    \n",
    "    # Img 1:\n",
    "    p1 = figure(plot_width=plotwidth, plot_height=int(plotwidth*img1.shape[0]/img1.shape[1]), \n",
    "                title=title1, toolbar_location=\"above\")\n",
    "    p1.image(image=[img1], x=0, y=0, dw=img1.shape[1], dh=img1.shape[0], palette=\"Plasma256\")\n",
    "    p1.line((col, col), (0, img1.shape[0]), line_alpha=0.7, line_color=\"white\")\n",
    "    p1.line((0, img1.shape[1]), (line, line), line_alpha=0.7, line_color=\"white\")\n",
    "\n",
    "\n",
    "    # Img 2\n",
    "    p2 = figure(plot_width=plotwidth, plot_height=int(plotwidth*img2.shape[0]/img2.shape[1]), \n",
    "               title=title2, toolbar_location=\"above\")\n",
    "    p2.image(image=[img2], x=0, y=0, dw=img2.shape[1], dh=img2.shape[0], palette=\"Plasma256\")\n",
    "    p2.line((col, col), (0, img2.shape[0]), line_alpha=0.7, line_color=\"white\")\n",
    "    p2.line((0, img2.shape[1]), (line, line), line_alpha=0.7, line_color=\"white\")\n",
    "\n",
    "\n",
    "    # Horizontal profile:\n",
    "    maxx = np.amax(img1[line,:])\n",
    "    if np.amax(img2[line,:])>maxx: maxx = np.amax(img2[line,:])\n",
    "        \n",
    "    p3 = figure(plot_width=plotwidth, plot_height=int(plotwidth*2/3), title=\"x profile\", \n",
    "                toolbar_location=\"above\", y_range=(0, int(1.05*maxx)))\n",
    "    x3 = np.arange(0, len(img1[line,:]), 1)\n",
    "    x3b = np.arange(0, len(img2[line,:]), 1)\n",
    "    p3.line(x3, img1[line,:], line_width=2, line_color=colorprofile1, legend_label=title1)\n",
    "    p3.line(x3b, img2[line,:], line_width=2, line_color=colorprofile2, legend_label=title2)\n",
    "    p3.legend.click_policy=\"hide\"\n",
    "\n",
    "\n",
    "    # Vertical profile:\n",
    "    p4 = figure(plot_width=plotwidth, plot_height=int(plotwidth*2/3), title=\"y profile\", toolbar_location=\"above\")\n",
    "    x4 = np.arange(0, len(img1[:,col]), 1)\n",
    "    x4b = np.arange(0, len(img2[:,col]), 1)\n",
    "    p4.line(x4, img1[:, col], line_width=3, line_color=colorprofile1, legend_label=title1)\n",
    "    p4.line(x4b, img2[:, col], line_width=3, line_color=colorprofile2, legend_label=title2)\n",
    "    p4.legend.click_policy=\"hide\"\n",
    "\n",
    "\n",
    "    # Layout & show:\n",
    "    grid = gridplot([[p1, p2], [p3, p4]])\n",
    "    show(grid)\n",
    "\n",
    "    \n",
    "    \n",
    "# Converts the RGB image to RGBA for display\n",
    "#   \n",
    "# @params:\n",
    "#  array: image RGB array\n",
    "#  sizex: x size of the image\n",
    "#  sizey: y size of the image\n",
    "def convertToRGBA(array, sizex, sizey):\n",
    "\n",
    "    # creates a new rgba img and copy the tiff values in it\n",
    "    rgba = np.empty((sizey,sizex), dtype=np.uint32)\n",
    "    view = rgba.view(dtype=np.uint8).reshape((sizey, sizex, 4))\n",
    "    view[:,:,0] = array[:,:,0]/65535.0*255.0\n",
    "    view[:,:,1] = array[:,:,1]/65535.0*255.0\n",
    "    view[:,:,2] = array[:,:,2]/65535.0*255.0\n",
    "    view[:,:,3] = 255\n",
    "\n",
    "    return rgba\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Reads all images and returns the median image\n",
    "#   \n",
    "# @params:\n",
    "#  array: image RGB array\n",
    "#  sizex: x size of the image\n",
    "#  sizey: y size of the image\n",
    "def medianImage(path, filename, firstNb, fileExtension, nbOfImgs):\n",
    "\n",
    "    img = sitk.ReadImage(path+filename+str(firstNb)+fileExtension)\n",
    "\n",
    "    size = (sitk.GetArrayFromImage(img).shape[0], \n",
    "            sitk.GetArrayFromImage(img).shape[1], \n",
    "            sitk.GetArrayFromImage(img).shape[2], \n",
    "            nbOfImgs)\n",
    "    \n",
    "    imgs = np.zeros(size)\n",
    "    \n",
    "    for i in range(nbOfImgs):\n",
    "        img = sitk.ReadImage(path+filename+str(firstNb+i)+fileExtension)\n",
    "        imgs[:,:,:,i] = sitk.GetArrayFromImage(img)\n",
    "\n",
    "    medianImg = np.median(imgs, axis=3)\n",
    "\n",
    "    return medianImg\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Displays two images and profiles\n",
    "#   \n",
    "# @params:\n",
    "#  img1: image array 1\n",
    "#  img2: image array 2\n",
    "#  col: column nb for the profile\n",
    "#  line: line nb for the profile\n",
    "def compare2Imgs(img1, img2, col, line, plotwidth=450, title1='dose image 1', title2='dose image 2',\n",
    "                colorprofile1='firebrick', colorprofile2='darkblue'): \n",
    "    \n",
    "    # Img 1:\n",
    "    p1 = figure(plot_width=plotwidth, plot_height=int(plotwidth*img1.shape[0]/img1.shape[1]), \n",
    "                title=title1, toolbar_location=\"above\")\n",
    "    p1.image(image=[img1], x=0, y=0, dw=img1.shape[1], dh=img1.shape[0], palette=\"Plasma256\")\n",
    "    p1.line((col, col), (0, img1.shape[0]), line_alpha=0.7, line_color=\"white\")\n",
    "    p1.line((0, img1.shape[1]), (line, line), line_alpha=0.7, line_color=\"white\")\n",
    "\n",
    "\n",
    "    # Img 2\n",
    "    p2 = figure(plot_width=plotwidth, plot_height=int(plotwidth*img2.shape[0]/img2.shape[1]), \n",
    "               title=title2, toolbar_location=\"above\")\n",
    "    p2.image(image=[img2], x=0, y=0, dw=img2.shape[1], dh=img2.shape[0], palette=\"Plasma256\")\n",
    "    p2.line((col, col), (0, img2.shape[0]), line_alpha=0.7, line_color=\"white\")\n",
    "    p2.line((0, img2.shape[1]), (line, line), line_alpha=0.7, line_color=\"white\")\n",
    "\n",
    "\n",
    "    # Horizontal profile:\n",
    "    maxx = np.amax(img1[line,:])\n",
    "    if np.amax(img2[line,:])>maxx: maxx = np.amax(img2[line,:])\n",
    "        \n",
    "    p3 = figure(plot_width=plotwidth, plot_height=int(plotwidth*2/3), title=\"x profile\", \n",
    "                toolbar_location=\"above\", y_range=(0, int(1.05*maxx)))\n",
    "    x3 = np.arange(0, len(img1[line,:]), 1)\n",
    "    x3b = np.arange(0, len(img2[line,:]), 1)\n",
    "    p3.line(x3, img1[line,:], line_width=2, line_color=colorprofile1, legend_label=title1)\n",
    "    p3.line(x3b, img2[line,:], line_width=2, line_color=colorprofile2, legend_label=title2)\n",
    "\n",
    "\n",
    "    # Vertical profile:\n",
    "    p4 = figure(plot_width=plotwidth, plot_height=int(plotwidth*2/3), title=\"y profile\", toolbar_location=\"above\")\n",
    "    x4 = np.arange(0, len(img1[:,col]), 1)\n",
    "    x4b = np.arange(0, len(img2[:,col]), 1)\n",
    "    p4.line(x4, img1[:, col], line_width=3, line_color=colorprofile1, legend_label=title1)\n",
    "    p4.line(x4b, img2[:, col], line_width=3, line_color=colorprofile2, legend_label=title2)\n",
    "\n",
    "    grid = gridplot([[p1, p2], [p3, p4]])\n",
    "\n",
    "\n",
    "    show(grid)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Displays two images and profiles\n",
    "#   \n",
    "# @params:\n",
    "#  img1: image array 1\n",
    "#  img2: image array 2\n",
    "#  col: column nb for the profile\n",
    "#  line: line nb for the profile\n",
    "def dispImgAndProf(img, col, line, plotwidth=450, title='dose image 1', colorprofile='firebrick'): \n",
    "    \n",
    "    # Img 1:\n",
    "    p1 = figure(plot_width=plotwidth, plot_height=int(plotwidth*img.shape[0]/img.shape[1]), \n",
    "                title=title, toolbar_location=\"above\")\n",
    "    p1.image(image=[img], x=0, y=0, dw=img.shape[1], dh=img.shape[0], palette=\"Plasma256\")\n",
    "    p1.line((col, col), (0, img.shape[0]), line_alpha=0.7, line_color=\"white\")\n",
    "    p1.line((0, img.shape[1]), (line, line), line_alpha=0.7, line_color=\"white\")\n",
    "\n",
    "\n",
    "    # Horizontal profile:\n",
    "    maxx = np.amax(img[line,:])\n",
    "        \n",
    "    p3 = figure(plot_width=plotwidth, plot_height=int(plotwidth*2/3), title=\"x profile\", \n",
    "                toolbar_location=\"above\", y_range=(0, int(1.05*maxx)))\n",
    "    x3 = np.arange(0, len(img[line,:]), 1)\n",
    "    p3.line(x3, img[line,:], line_width=2, line_color=colorprofile, legend_label=title)\n",
    "\n",
    "\n",
    "    # Vertical profile:\n",
    "    p4 = figure(plot_width=plotwidth, plot_height=int(plotwidth*2/3), title=\"y profile\", toolbar_location=\"above\")\n",
    "    x4 = np.arange(0, len(img[:,col]), 1)\n",
    "    p4.line(x4, img[:, col], line_width=3, line_color=colorprofile, legend_label=title)\n",
    "\n",
    "    grid = gridplot([[p3, p4]])\n",
    "\n",
    "    show(p1)\n",
    "    show(grid)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Registers two images and return the moving img registered on the ref. img.\n",
    "#   \n",
    "# @params:\n",
    "#  refImg: reference image\n",
    "#  movingImg: moving image\n",
    "def registerImgs(refImg, movingImg):\n",
    "\n",
    "    # Initial transform:\n",
    "    fixedimg = sitk.Image(refImg.shape[1], refImg.shape[0], sitk.sitkFloat32)\n",
    "    for i in range(refImg.shape[1]):\n",
    "        for j in range(refImg.shape[0]):\n",
    "            fixedimg.SetPixel(i, j, float(refImg[j,i]))\n",
    "\n",
    "    movingimg = sitk.Image(movingImg.shape[1], movingImg.shape[0], sitk.sitkFloat32)\n",
    "    for i in range(movingImg.shape[1]):\n",
    "        for j in range(movingImg.shape[0]):\n",
    "            movingimg.SetPixel(i, j, float(movingImg[j,i]))\n",
    "\n",
    "    initial_transform = sitk.CenteredTransformInitializer(fixedimg, \n",
    "                                                          movingimg, \n",
    "                                                          sitk.Euler2DTransform(), \n",
    "                                                          sitk.CenteredTransformInitializerFilter.GEOMETRY)\n",
    "\n",
    "    \n",
    "    # Real registration:\n",
    "    registration_method = sitk.ImageRegistrationMethod()\n",
    "\n",
    "    # Similarity metric settings:\n",
    "    registration_method.SetMetricAsMeanSquares()\n",
    "    registration_method.SetMetricSamplingStrategy(registration_method.RANDOM)\n",
    "    registration_method.SetMetricSamplingPercentage(0.2)\n",
    "    registration_method.SetInterpolator(sitk.sitkLinear)\n",
    "\n",
    "\n",
    "    # Optimizer settings.\n",
    "    registration_method.SetOptimizerAsRegularStepGradientDescent(learningRate=1.0, minStep=0.01, \n",
    "                                                                 numberOfIterations=1000, relaxationFactor=0.5)\n",
    "    registration_method.SetOptimizerScalesFromPhysicalShift()\n",
    "    registration_method.SetInitialTransform(initial_transform, inPlace=False)\n",
    "    final_transform = registration_method.Execute(sitk.Cast(fixedimg, sitk.sitkFloat32), \n",
    "                                                  sitk.Cast(movingimg, sitk.sitkFloat32))\n",
    "    finalimg = sitk.Resample(movingimg, fixedimg, final_transform, sitk.sitkBSplineResamplerOrder5, 0.0, \n",
    "                             movingimg.GetPixelID())\n",
    "    \n",
    "    # Returns the resulting image:\n",
    "    return sitk.GetArrayFromImage(finalimg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTES LATERAL CORRECTION COEFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >>> iMAGES rEAD !\n"
     ]
    }
   ],
   "source": [
    "# READS THE IMAGES:\n",
    "# <!> ne pas mettre d'accent dans les chemins et noms de fichiers\n",
    "\n",
    "# Version généralisée: on doit pouvoir mettre autant d'images que l'on souhaite\n",
    "# Peut etre faut-il renseigner les centres ? ou decomposer le champ de vue en \n",
    "# régions égales en taille?\n",
    "\n",
    "\n",
    "# Inputs:\n",
    "m_path = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/corrLaterale/'\n",
    "\n",
    "m_fileName = 'pos'\n",
    "\n",
    "m_firstPosNb = 1\n",
    "m_nbOfPos = 10\n",
    "\n",
    "m_firstImgNb = 1\n",
    "m_nbOfImgsPerPos = 1\n",
    "\n",
    "m_fileExtension = \".tif\"\n",
    "\n",
    "m_nbRoisPerPos = 4\n",
    "m_roiCenters = [35, 90, 140, 200]\n",
    "m_roiHeight = 30\n",
    "m_roiWidth = 16\n",
    "\n",
    "m_dimViewer = 900\n",
    "m_subfactor = 10\n",
    "\n",
    "visu = False\n",
    "m_beginRight = True\n",
    "\n",
    "\n",
    "# Reading the images and creates an image having all positions:\n",
    "\n",
    "# Reading first image:\n",
    "img = medianImage(m_path, m_fileName+str(m_firstPosNb)+'_0', m_firstImgNb, m_fileExtension, m_nbOfImgsPerPos)\n",
    "img = subSampleRGBArray(img, m_subfactor)\n",
    "\n",
    "# creates the output image for calibration\n",
    "calibImg = np.zeros(img.shape)\n",
    "\n",
    "# variables to be used for cropping the images:\n",
    "m_step = img.shape[1] / m_nbOfPos\n",
    "m_layerPos = int(m_step/2-1)\n",
    "if m_beginRight: \n",
    "    m_layerPos = (img.shape[1]-1) - m_layerPos\n",
    "m_halfwidth = int(m_step/2-1)\n",
    "\n",
    "# cropping first image and records it in the calibration image:\n",
    "calibImg[:,m_layerPos-m_halfwidth:m_layerPos+m_halfwidth,:] = img[:,m_layerPos-m_halfwidth:m_layerPos+m_halfwidth,:]\n",
    "\n",
    "# for loop to read all other images:\n",
    "for i in range(1, m_nbOfPos):\n",
    "    img = medianImage(m_path, m_fileName+str(m_firstPosNb+i)+'_0', m_firstImgNb, m_fileExtension, m_nbOfImgsPerPos)\n",
    "    img = subSampleRGBArray(img, m_subfactor)\n",
    "    \n",
    "    m_layerPos = int((i+0.5)*m_step-1)\n",
    "    if m_beginRight:\n",
    "        m_layerPos = (img.shape[1]-1) - m_layerPos\n",
    "\n",
    "    calibImg[:,m_layerPos-m_halfwidth:m_layerPos+m_halfwidth,:] = img[:,m_layerPos-m_halfwidth:m_layerPos+m_halfwidth,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Visualization:\n",
    "if visu:\n",
    "    \n",
    "    # draws the image :\n",
    "    p = figure(plot_width=m_dimViewer, plot_height=int(m_dimViewer*calibImg.shape[0]/calibImg.shape[1]), \n",
    "                   title='Calibration image', toolbar_location=\"above\")\n",
    "    p.image(image=[calibImg[:,:,0]], x=0, y=0, dw=calibImg.shape[1], dh=calibImg.shape[0], palette=\"Greys256\")\n",
    "\n",
    "    # draws ROIs used for calibration:\n",
    "    for i in range(m_nbOfPos):\n",
    "        m_layerPos = int((i+0.5)*m_step-1)\n",
    "        if m_beginRight:\n",
    "            m_layerPos = (img.shape[1]-1) - m_layerPos\n",
    "        for j in range(len(m_roiCenters)):\n",
    "            p.rect(x=m_layerPos, \n",
    "                   y=m_roiCenters[j], \n",
    "                   width=m_roiWidth,\n",
    "                   height=m_roiHeight,\n",
    "                   fill_alpha=0,\n",
    "                   line_color=\"firebrick\",\n",
    "                   line_alpha=1\n",
    "              )\n",
    "\n",
    "    show(p)\n",
    "    \n",
    "\n",
    "    \n",
    "print('   >>> iMAGES rEAD !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >>> cOEFFICIENTS cALCULATED !\n"
     ]
    }
   ],
   "source": [
    "# CORRECTION FACTORS DETERMINATION\n",
    "#   Correction Factors calculated in Lewis et al. Med Phys january 2015\n",
    "\n",
    "visu = False\n",
    "\n",
    "def func(x, a, b):\n",
    "    return a + b*x\n",
    "\n",
    "\n",
    "# Postioning array: (where the coefficients are calculated) in mm\n",
    "#  The films are now scanned in 254ppp and resized to 25.4ppp which means 1pix/mm\n",
    "#  This code only works in this case (1pix/mm)\n",
    "#  It should be changed in future implementations!\n",
    "m_posArr = []\n",
    "for i in range(m_nbOfPos):\n",
    "    m_posArr.append(int((i+0.5)*m_step-1))\n",
    "\n",
    "\n",
    "# Center grey values (RGB) calculation:\n",
    "vr_center = []\n",
    "vg_center = []\n",
    "vb_center = []\n",
    "\n",
    "roiHalfWidth = int(m_roiWidth/2)\n",
    "roiHalfHeight = int(m_roiHeight/2)\n",
    "\n",
    "if m_nbOfPos%2 == 0:\n",
    "    m_layerPos1 = int((m_nbOfPos/2+0.5)*m_step-1)\n",
    "    if m_beginRight:\n",
    "        m_layerPos1 = (img.shape[1]-1) - m_layerPos1\n",
    "\n",
    "    m_layerPos2 = int((m_nbOfPos/2-0.5)*m_step-1)\n",
    "    if m_beginRight:\n",
    "        m_layerPos2 = (img.shape[1]-1) - m_layerPos2\n",
    "    \n",
    "    vr1 = []\n",
    "    vg1 = []\n",
    "    vb1 = []\n",
    "    for i in range(m_nbRoisPerPos):\n",
    "        vr1.append(np.mean(calibImg[m_roiCenters[i]-roiHalfHeight:m_roiCenters[i]+roiHalfHeight,\n",
    "                               m_layerPos1-roiHalfWidth:m_layerPos1+roiHalfWidth, 0]))\n",
    "        vg1.append(np.mean(calibImg[m_roiCenters[i]-roiHalfHeight:m_roiCenters[i]+roiHalfHeight,\n",
    "                               m_layerPos1-roiHalfWidth:m_layerPos1+roiHalfWidth, 1]))\n",
    "        vb1.append(np.mean(calibImg[m_roiCenters[i]-roiHalfHeight:m_roiCenters[i]+roiHalfHeight,\n",
    "                               m_layerPos1-roiHalfWidth:m_layerPos1+roiHalfWidth, 2]))\n",
    "\n",
    "    vr2 = []\n",
    "    vg2 = []\n",
    "    vb2 = []\n",
    "    for i in range(m_nbRoisPerPos):\n",
    "        vr2.append(np.mean(calibImg[m_roiCenters[i]-roiHalfHeight:m_roiCenters[i]+roiHalfHeight,\n",
    "                               m_layerPos2-roiHalfWidth:m_layerPos2+roiHalfWidth, 0]))\n",
    "        vg2.append(np.mean(calibImg[m_roiCenters[i]-roiHalfHeight:m_roiCenters[i]+roiHalfHeight,\n",
    "                               m_layerPos2-roiHalfWidth:m_layerPos2+roiHalfWidth, 1]))\n",
    "        vb2.append(np.mean(calibImg[m_roiCenters[i]-roiHalfHeight:m_roiCenters[i]+roiHalfHeight,\n",
    "                               m_layerPos2-roiHalfWidth:m_layerPos2+roiHalfWidth, 2]))\n",
    "\n",
    "    for i in range(m_nbRoisPerPos):\n",
    "        vr_center.append((vr1[i]+vr2[i])/2)\n",
    "        vg_center.append((vg1[i]+vg2[i])/2)\n",
    "        vb_center.append((vb1[i]+vb2[i])/2)\n",
    "    \n",
    "else:\n",
    "    m_layerPos = int((m_nbOfPos/2)*m_step-1)\n",
    "    if m_beginRight:\n",
    "        m_layerPos = (img.shape[1]-1) - m_layerPos1\n",
    "\n",
    "    for i in range(m_nbRoisPerPos):\n",
    "        vr_center.append(np.mean(calibImg[m_roiCenters[i]-roiHalfHeight:m_roiCenters[i]+roiHalfHeight,\n",
    "                               m_layerPos-roiHalfWidth:m_layerPos+roiHalfWidth, 0]))\n",
    "        vg_center.append(np.mean(calibImg[m_roiCenters[i]-roiHalfHeight:m_roiCenters[i]+roiHalfHeight,\n",
    "                               m_layerPos-roiHalfWidth:m_layerPos+roiHalfWidth, 1]))\n",
    "        vb_center.append(np.mean(calibImg[m_roiCenters[i]-roiHalfHeight:m_roiCenters[i]+roiHalfHeight,\n",
    "                               m_layerPos-roiHalfWidth:m_layerPos+roiHalfWidth, 2]))\n",
    "\n",
    "\n",
    "# finding the parameters A and B for each channel and position:\n",
    "Ar = []\n",
    "Br = []\n",
    "Ag = []\n",
    "Bg = []\n",
    "Ab = []\n",
    "Bb = []\n",
    "\n",
    "for i in range(m_nbOfPos):\n",
    "    vr = []\n",
    "    vg = []\n",
    "    vb = []\n",
    "    \n",
    "    m_layerPos = int((i+0.5)*m_step-1)\n",
    "    if m_beginRight:  # is it necessary? needs to be checked...\n",
    "        m_layerPos = (img.shape[1]-1) - m_layerPos\n",
    "    \n",
    "    for j in range(m_nbRoisPerPos):\n",
    "        vr.append(np.mean(calibImg[m_roiCenters[j]-roiHalfHeight:m_roiCenters[j]+roiHalfHeight,\n",
    "                           m_layerPos-roiHalfWidth:m_layerPos+roiHalfWidth, 0]))\n",
    "        vg.append(np.mean(calibImg[m_roiCenters[j]-roiHalfHeight:m_roiCenters[j]+roiHalfHeight,\n",
    "                           m_layerPos-roiHalfWidth:m_layerPos+roiHalfWidth, 1]))\n",
    "        vb.append(np.mean(calibImg[m_roiCenters[j]-roiHalfHeight:m_roiCenters[j]+roiHalfHeight,\n",
    "                           m_layerPos-roiHalfWidth:m_layerPos+roiHalfWidth, 2]))\n",
    "\n",
    "    params, cov = optimize.curve_fit(func, vr, vr_center)\n",
    "    Ar.append(params[0])\n",
    "    Br.append(params[1])\n",
    "\n",
    "    params, cov = optimize.curve_fit(func, vg, vg_center)\n",
    "    Ag.append(params[0])\n",
    "    Bg.append(params[1])\n",
    "\n",
    "    params, cov = optimize.curve_fit(func, vb, vb_center)\n",
    "    Ab.append(params[0])\n",
    "    Bb.append(params[1])\n",
    "\n",
    "if m_beginRight:\n",
    "    Ar = np.flip(Ar)\n",
    "    Ag = np.flip(Ag)\n",
    "    Ab = np.flip(Ab)\n",
    "    Br = np.flip(Br)\n",
    "    Bg = np.flip(Bg)\n",
    "    Bb = np.flip(Bb)\n",
    "    \n",
    "    \n",
    "# data visualization:\n",
    "signSize = 5\n",
    "alpha = 0.5 \n",
    "\n",
    "if visu:\n",
    "    p1 = figure(plot_width=700, plot_height=500, title=\"A values\", toolbar_location=\"above\",\n",
    "               x_axis_label='Lateral position (mm)', y_axis_label='Coefficient A')\n",
    "    p1.line(m_posArr, Ar, line_width=2, color='firebrick')\n",
    "    p1.line(m_posArr, Ag, line_width=2, color='darkgreen')\n",
    "    p1.line(m_posArr, Ab, line_width=2, color='darkblue')\n",
    "    \n",
    "    p2 = figure(plot_width=700, plot_height=500, title=\"B values\", toolbar_location=\"above\",\n",
    "               x_axis_label='Lateral position (mm)', y_axis_label='Coefficient B')\n",
    "    p2.line(m_posArr, Br, line_width=2, color='firebrick')\n",
    "    p2.line(m_posArr, Bg, line_width=2, color='darkgreen')\n",
    "    p2.line(m_posArr, Bb, line_width=2, color='darkblue')\n",
    "\n",
    "    grid = gridplot([[p1], [p2]])\n",
    "    show(grid)\n",
    "\n",
    "\n",
    "print('   >>> cOEFFICIENTS cALCULATED !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   >>> mODELS dONE!\n"
     ]
    }
   ],
   "source": [
    "# CORRECTION MODELS FITTING: \n",
    "\n",
    "\n",
    "# To visualize results:\n",
    "visu = False\n",
    "\n",
    "\n",
    "fAr_lin = interp1d(m_posArr, Ar, kind='linear')  # kind = cubic, linear, ...\n",
    "fAg_lin = interp1d(m_posArr, Ag, kind='linear')\n",
    "fAb_lin = interp1d(m_posArr, Ab, kind='linear')\n",
    "\n",
    "fBr_lin = interp1d(m_posArr, Br, kind='linear')\n",
    "fBg_lin = interp1d(m_posArr, Bg, kind='linear')\n",
    "fBb_lin = interp1d(m_posArr, Bb, kind='linear')\n",
    "\n",
    "\n",
    "if visu:\n",
    "    x = m_posArr\n",
    "    xnew = np.arange(int(np.min(x)), int(np.max(x)))\n",
    "    \n",
    "    p1 = figure(plot_width=300, plot_height=300, title=\"Ar values\", toolbar_location=\"above\",\n",
    "               x_axis_label='Lateral position (mm)', y_axis_label='Coefficient A')\n",
    "    p1.circle(x, Ar, size=5, color='firebrick', alpha=0.5)\n",
    "    p1.line(xnew, fAr_lin(xnew), line_width=1, color='firebrick', line_dash='dashed')\n",
    "\n",
    "    p2 = figure(plot_width=300, plot_height=300, title=\"Ag values\", toolbar_location=\"above\",\n",
    "               x_axis_label='Lateral position (mm)', y_axis_label='Coefficient A')\n",
    "    p2.circle(x, Ag, size=5, color='darkgreen', alpha=0.5)\n",
    "    p2.line(xnew, fAg_lin(xnew), line_width=1, color='darkgreen', line_dash='dashed')\n",
    "\n",
    "    p3 = figure(plot_width=300, plot_height=300, title=\"Ab values\", toolbar_location=\"above\",\n",
    "               x_axis_label='Lateral position (mm)', y_axis_label='Coefficient A')\n",
    "    p3.circle(x, Ab, size=5, color='darkblue', alpha=0.5)\n",
    "    p3.line(xnew, fAb_lin(xnew), line_width=1, color='darkblue', line_dash='dashed')\n",
    "\n",
    "#     p1.line(x, Ag, line_width=2, color='darkgreen')\n",
    "#     p1.line(x, Ab, line_width=2, color='darkblue')\n",
    "    \n",
    "    p4 = figure(plot_width=300, plot_height=300, title=\"Br values\", toolbar_location=\"above\",\n",
    "               x_axis_label='Lateral position (mm)', y_axis_label='Coefficient A')\n",
    "    p4.circle(x, Br, size=5, color='firebrick', alpha=0.5)\n",
    "    p4.line(xnew, fBr_lin(xnew), line_width=1, color='firebrick', line_dash='dashed')\n",
    "\n",
    "    p5 = figure(plot_width=300, plot_height=300, title=\"Bg values\", toolbar_location=\"above\",\n",
    "               x_axis_label='Lateral position (mm)', y_axis_label='Coefficient A')\n",
    "    p5.circle(x, Bg, size=5, color='darkgreen', alpha=0.5)\n",
    "    p5.line(xnew, fBg_lin(xnew), line_width=1, color='darkgreen', line_dash='dashed')\n",
    "\n",
    "    p6 = figure(plot_width=300, plot_height=300, title=\"Bb values\", toolbar_location=\"above\",\n",
    "               x_axis_label='Lateral position (mm)', y_axis_label='Coefficient A')\n",
    "    p6.circle(x, Bb, size=5, color='darkblue', alpha=0.5)\n",
    "    p6.line(xnew, fBb_lin(xnew), line_width=1, color='darkblue', line_dash='dashed')\n",
    "\n",
    "    grid1 = gridplot([[p1,p2,p3],[p4,p5,p6]])\n",
    "    show(grid1)\n",
    "\n",
    "print(\"   >>> mODELS dONE!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATERAL CORRECTION & CONVERSION TO DOSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# IMAGE CORRECTION AND CONVERSION TO DOSE:\n",
    "\n",
    "\n",
    "# Variables:\n",
    "path = 'testRBGB/'\n",
    "nbOfFiles = 1\n",
    "firstNb = 1\n",
    "filesName = \"testRBGB_00\"\n",
    "fileExtension = \".tif\"\n",
    "splineFile = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/scan 24h/bSpline_normalCalib.txt'\n",
    "splineFileWithLatCorr = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/scan 24h/bSpline_calibWithLateralCorr.txt'\n",
    "pixsize = 1\n",
    "\n",
    "# Reading the file:\n",
    "try:\n",
    "    g = Radiochromic_RB(path+filesName, firstNb, nbOfFiles, fileExtension=fileExtension)\n",
    "    g.subSampleDataArray(10)\n",
    "    doseImg_noCorr = g.convertToDose_cubicSplineFit(splineFile, 1500)\n",
    "    array = g.getArray()\n",
    "\n",
    "    # correcting lateral response\n",
    "    corrArray = np.zeros(array.shape)\n",
    "    for i in range(array.shape[1]):\n",
    "        posx = i*pixsize  # peut être faire plus précis ensuite..\n",
    "        if posx<np.amin(m_posArr):\n",
    "            posx = np.amin(m_posArr)\n",
    "        elif posx>np.amax(m_posArr):\n",
    "            posx = np.amax(m_posArr)\n",
    "        \n",
    "        _Ar = fAr_lin(posx)\n",
    "        _Ag = fAg_lin(posx)\n",
    "        _Ab = fAb_lin(posx)\n",
    "        _Br = fBr_lin(posx)\n",
    "        _Bg = fBg_lin(posx)\n",
    "        _Bb = fBb_lin(posx)\n",
    "        corrArray[:,i,0] = _Ar + _Br*array[:,i,0]\n",
    "        corrArray[:,i,1] = _Ag + _Bg*array[:,i,1]\n",
    "        corrArray[:,i,2] = _Ab + _Bb*array[:,i,2]\n",
    "    \n",
    "    g.setArray(corrArray)\n",
    "    doseImg_corr = g.convertToDose_cubicSplineFit(splineFileWithLatCorr, 1500)\n",
    "except ValueError as err:\n",
    "    print('Erreur: '+err)\n",
    "\n",
    "    \n",
    "# compare2Imgs(doseImg_noCorr, doseImg_corr, 200, 100, plotwidth=450, \n",
    "#              title1=\"no corr.\", title2=\"corr.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MULTIPLE IMAGES TEST R/B method:\n",
    "\n",
    "\n",
    "# Variables:\n",
    "path = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/testLateral/'\n",
    "nbOfFiles = 1\n",
    "firstNb = 1\n",
    "refImgName = \"test-pos04_0\"\n",
    "fileExtension = \".tif\"\n",
    "splineFile = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/scan 24h/bSpline_normalCalib.txt'\n",
    "splineFileWithLatCorr = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/scan 24h/bSpline_calibWithLateralCorr.txt'\n",
    "pixsize = 1\n",
    "\n",
    "otherImgNames = [\"test-pos01_0\", \"test-pos02_0\", \"test-pos03_0\", \"test-pos05_0\", \n",
    "                 \"test-pos06_0\", \"test-pos07_0\", \"test-pos08_0\"]\n",
    "\n",
    "rect_ref = [95,90,245,180]\n",
    "\n",
    "rect_imgs = [[0, 90, 140, 180],\n",
    "            [25,90,165,180],\n",
    "            [65,90,205,180],\n",
    "            [125,90,265,180],\n",
    "            [155,90,295,180],\n",
    "            [160,90,300,180],\n",
    "            [168,90,308,180]]\n",
    "\n",
    "m_dosemax = 700\n",
    "\n",
    "visu = True\n",
    "dimViewer = 480\n",
    "regImgNbToDisp = 1\n",
    "line = 50\n",
    "col = 50\n",
    "\n",
    "\n",
    "# Reading the files:\n",
    "try:\n",
    "    # Opens reference image:\n",
    "    g = Radiochromic_RB(path+refImgName, firstNb, nbOfFiles, fileExtension=fileExtension)\n",
    "    g.subSampleDataArray(10)\n",
    "    \n",
    "    refImg_noCorr = g.convertToDose_cubicSplineFit(splineFile, m_dosemax)[rect_ref[1]:rect_ref[3],\n",
    "                                                                          rect_ref[0]:rect_ref[2]]\n",
    "\n",
    "    # correcting lateral response\n",
    "    array = g.getArray()\n",
    "    corrArray = np.zeros(array.shape)\n",
    "    for i in range(array.shape[1]):\n",
    "        posx = i*pixsize  # peut être faire plus précis ensuite..\n",
    "        if posx<np.amin(m_posArr):\n",
    "            posx = np.amin(m_posArr)\n",
    "        elif posx>np.amax(m_posArr):\n",
    "            posx = np.amax(m_posArr)\n",
    "        \n",
    "        _Ar = fAr_lin(posx)\n",
    "        _Ag = fAg_lin(posx)\n",
    "        _Ab = fAb_lin(posx)\n",
    "        _Br = fBr_lin(posx)\n",
    "        _Bg = fBg_lin(posx)\n",
    "        _Bb = fBb_lin(posx)\n",
    "        corrArray[:,i,0] = _Ar + _Br*array[:,i,0]\n",
    "        corrArray[:,i,1] = _Ag + _Bg*array[:,i,1]\n",
    "        corrArray[:,i,2] = _Ab + _Bb*array[:,i,2]\n",
    "    \n",
    "    g.setArray(corrArray)\n",
    "    refImg_corr = g.convertToDose_cubicSplineFit(splineFileWithLatCorr, 1500)[rect_ref[1]:rect_ref[3],\n",
    "                                                                          rect_ref[0]:rect_ref[2]]\n",
    "\n",
    "    # Opens all other images:\n",
    "    imgs = np.zeros([refImg_noCorr.shape[0], refImg_noCorr.shape[1], len(otherImgNames)])\n",
    "    imgs_corr = np.zeros([refImg_noCorr.shape[0], refImg_noCorr.shape[1], len(otherImgNames)])\n",
    "    for i in range(len(otherImgNames)):\n",
    "        g = Radiochromic_RB(path+otherImgNames[i], firstNb, nbOfFiles, fileExtension=fileExtension)\n",
    "        g.subSampleDataArray(10)\n",
    "        \n",
    "        img = g.convertToDose_cubicSplineFit(splineFile, m_dosemax)[rect_imgs[i][1]:rect_imgs[i][3],\n",
    "                                                                    rect_imgs[i][0]:rect_imgs[i][2]]\n",
    "        \n",
    "        imgs[:,:,i] = registerImgs(refImg_noCorr, img)\n",
    "    \n",
    "        # correcting lateral response\n",
    "        array = g.getArray()\n",
    "        corrArray = np.zeros(array.shape)\n",
    "        for j in range(array.shape[1]):\n",
    "            posx = j*pixsize  # peut être faire plus précis ensuite..\n",
    "            if posx<np.amin(m_posArr):\n",
    "                posx = np.amin(m_posArr)\n",
    "            elif posx>np.amax(m_posArr):\n",
    "                posx = np.amax(m_posArr)\n",
    "        \n",
    "            _Ar = fAr_lin(posx)\n",
    "            _Ag = fAg_lin(posx)\n",
    "            _Ab = fAb_lin(posx)\n",
    "            _Br = fBr_lin(posx)\n",
    "            _Bg = fBg_lin(posx)\n",
    "            _Bb = fBb_lin(posx)\n",
    "            corrArray[:,j,0] = _Ar + _Br*array[:,j,0]\n",
    "            corrArray[:,j,1] = _Ag + _Bg*array[:,j,1]\n",
    "            corrArray[:,j,2] = _Ab + _Bb*array[:,j,2]\n",
    "    \n",
    "        g.setArray(corrArray)\n",
    "        imgcorr = g.convertToDose_cubicSplineFit(splineFileWithLatCorr, m_dosemax)[rect_imgs[i][1]:rect_imgs[i][3],\n",
    "                                                                    rect_imgs[i][0]:rect_imgs[i][2]]\n",
    "\n",
    "        imgs_corr[:,:,i] = registerImgs(refImg_noCorr, imgcorr)\n",
    "    \n",
    "except ValueError as err:\n",
    "    print('Erreur: '+err)\n",
    "\n",
    "    \n",
    "    \n",
    "# Visualization:    \n",
    "if visu:\n",
    "    img1 = refImg_noCorr\n",
    "    img2 = refImg_corr#imgs[:,:,regImgNbToDisp]\n",
    "    imgsProfile = imgs_corr\n",
    "    \n",
    "    # Img 1:\n",
    "    p1 = figure(plot_width=dimViewer, plot_height=int(dimViewer*img1.shape[0]/img1.shape[1]), \n",
    "                title='Reference image', toolbar_location=\"above\")\n",
    "    p1.image(image=[img1], x=0, y=0, dw=img1.shape[1], dh=img1.shape[0], palette=\"Plasma256\")\n",
    "    p1.line((col, col), (0, img1.shape[0]), line_alpha=0.7, line_color=\"white\")\n",
    "    p1.line((0, img1.shape[1]), (line, line), line_alpha=0.7, line_color=\"white\")\n",
    "\n",
    "\n",
    "    # Img 2\n",
    "    p2 = figure(plot_width=dimViewer, plot_height=int(dimViewer*img2.shape[0]/img2.shape[1]), \n",
    "               title='Registered image', toolbar_location=\"above\")\n",
    "    p2.image(image=[img2], x=0, y=0, dw=img2.shape[1], dh=img2.shape[0], palette=\"Plasma256\")\n",
    "    p2.line((col, col), (0, img2.shape[0]), line_alpha=0.7, line_color=\"white\")\n",
    "    p2.line((0, img2.shape[1]), (line, line), line_alpha=0.7, line_color=\"white\")\n",
    "\n",
    "\n",
    "    # Horizontal profile:\n",
    "    maxx = np.amax(img1[line,:])\n",
    "    if np.amax(img2[line,:])>maxx: maxx = np.amax(img2[line,:])\n",
    "        \n",
    "    p3 = figure(plot_width=dimViewer, plot_height=int(dimViewer*2/3), title=\"x profile\", \n",
    "                toolbar_location=\"above\", y_range=(0, int(1.05*maxx)))\n",
    "    x3 = np.arange(0, len(img1[line,:]), 1)\n",
    "    x3b = np.arange(0, len(img2[line,:]), 1)\n",
    "    p3.line(x3, img1[line,:], line_width=3, line_color='black', legend_label='Reference Image')\n",
    "    for i in range(len(otherImgNames)):\n",
    "        p3.line(x3, imgsProfile[line,:,i], line_width=1, line_color=colors[i])#, legend_label='pos no'+ str(i))\n",
    "    \n",
    "\n",
    "    # Vertical profile:\n",
    "    p4 = figure(plot_width=dimViewer, plot_height=int(dimViewer*2/3), title=\"y profile\", toolbar_location=\"above\")\n",
    "    x4 = np.arange(0, len(img1[:,col]), 1)\n",
    "    x4b = np.arange(0, len(img2[:,col]), 1)\n",
    "    p4.line(x4, img1[:, col], line_width=3, line_color='black', legend_label='Reference Image')\n",
    "    for i in range(len(otherImgNames)):\n",
    "        p4.line(x4, imgsProfile[:,col,i], line_width=2, line_color=colors[i])#, legend_label='pos no'+ str(i))\n",
    "\n",
    "    grid = gridplot([[p1, p2], [p3, p4]])\n",
    "\n",
    "\n",
    "    show(grid)\n",
    "    \n",
    "print(\"  >>> mULTIPLE iMAGE tEST dONE !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# MULTIPLE IMAGES TEST MULTILINEAR METHOD:\n",
    "\n",
    "\n",
    "# Variables:\n",
    "path = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/testLateral/'\n",
    "nbOfFiles = 1\n",
    "firstNb = 1\n",
    "refImgName = \"test-pos04_0\"\n",
    "fileExtension = \".tif\"\n",
    "calFile = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/scan 24h/multiLinearRegressionCoefficients_02282001.txt'\n",
    "calFileWithLatCorr = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/scan 24h/multiLinearRegressionCoefficients_02282001_lateralCorr.txt'\n",
    "pixsize = 1\n",
    "\n",
    "otherImgNames = [\"test-pos01_0\", \"test-pos02_0\", \"test-pos03_0\", \"test-pos05_0\", \n",
    "                 \"test-pos06_0\", \"test-pos07_0\", \"test-pos08_0\"]\n",
    "\n",
    "rect_ref = [95,90,245,180]\n",
    "\n",
    "rect_imgs = [[0,90,140,180],\n",
    "            [25,90,165,180],\n",
    "            [65,90,205,180],\n",
    "            [125,90,265,180],\n",
    "            [155,90,295,180],\n",
    "            [160,90,300,180],\n",
    "            [168,90,308,180]]\n",
    "\n",
    "rect_refCtrl = [220,110,240,150]\n",
    "\n",
    "rect_imgsCtrl = [[130,110,150,150],\n",
    "            [160,110,180,150],\n",
    "            [190,110,210,150],\n",
    "            [250,110,270,150],\n",
    "            [280,110,300,150],\n",
    "            [140,110,160,150],\n",
    "            [170,110,190,150]]\n",
    "\n",
    "\n",
    "m_dosemax = 700\n",
    "\n",
    "visu = True\n",
    "dimViewer = 480\n",
    "regImgNbToDisp = 1\n",
    "line = 50\n",
    "col = 50\n",
    "\n",
    "\n",
    "# Reading the files:\n",
    "try:\n",
    "    # Opens reference image:\n",
    "    g = Radiochromic_multilinear(path+refImgName, firstNb, nbOfFiles, fileExtension=fileExtension)\n",
    "    g.subSampleDataArray(10)\n",
    "    \n",
    "    g.readMultilinearRegressionFile(calFile)\n",
    "    refImg_noCorr = g.convertToDose(rect_ref, rect_refCtrl)\n",
    "\n",
    "    # correcting lateral response\n",
    "    array = g.getArray()\n",
    "    corrArray = np.zeros(array.shape)\n",
    "    for i in range(array.shape[1]):\n",
    "        posx = i*pixsize  # peut être faire plus précis ensuite..\n",
    "        if posx<np.amin(m_posArr):\n",
    "            posx = np.amin(m_posArr)\n",
    "        elif posx>np.amax(m_posArr):\n",
    "            posx = np.amax(m_posArr)\n",
    "        \n",
    "        _Ar = fAr_lin(posx)\n",
    "        _Ag = fAg_lin(posx)\n",
    "        _Ab = fAb_lin(posx)\n",
    "        _Br = fBr_lin(posx)\n",
    "        _Bg = fBg_lin(posx)\n",
    "        _Bb = fBb_lin(posx)\n",
    "        corrArray[:,i,0] = _Ar + _Br*array[:,i,0]\n",
    "        corrArray[:,i,1] = _Ag + _Bg*array[:,i,1]\n",
    "        corrArray[:,i,2] = _Ab + _Bb*array[:,i,2]\n",
    "    \n",
    "    g.setArray(corrArray)\n",
    "    g.readMultilinearRegressionFile(calFileWithLatCorr)\n",
    "    refImg_corr = g.convertToDose(rect_ref, rect_refCtrl)\n",
    "\n",
    "    # Opens all other images:\n",
    "    imgs = np.zeros([refImg_noCorr.shape[0], refImg_noCorr.shape[1], len(otherImgNames)])\n",
    "    imgs_corr = np.zeros([refImg_noCorr.shape[0], refImg_noCorr.shape[1], len(otherImgNames)])\n",
    "    for i in range(len(otherImgNames)):\n",
    "        g = Radiochromic_multilinear(path+otherImgNames[i], firstNb, nbOfFiles, fileExtension=fileExtension)\n",
    "        g.subSampleDataArray(10)\n",
    "        \n",
    "        g.readMultilinearRegressionFile(calFile)\n",
    "        img = g.convertToDose(rect_imgs[i], rect_imgsCtrl[i])\n",
    "        \n",
    "        imgs[:,:,i] = registerImgs(refImg_noCorr, img)\n",
    "    \n",
    "        # correcting lateral response\n",
    "        array = g.getArray()\n",
    "        corrArray = np.zeros(array.shape)\n",
    "        for j in range(array.shape[1]):\n",
    "            posx = j*pixsize  # peut être faire plus précis ensuite..\n",
    "            if posx<np.amin(m_posArr):\n",
    "                posx = np.amin(m_posArr)\n",
    "            elif posx>np.amax(m_posArr):\n",
    "                posx = np.amax(m_posArr)\n",
    "        \n",
    "            _Ar = fAr_lin(posx)\n",
    "            _Ag = fAg_lin(posx)\n",
    "            _Ab = fAb_lin(posx)\n",
    "            _Br = fBr_lin(posx)\n",
    "            _Bg = fBg_lin(posx)\n",
    "            _Bb = fBb_lin(posx)\n",
    "            corrArray[:,j,0] = _Ar + _Br*array[:,j,0]\n",
    "            corrArray[:,j,1] = _Ag + _Bg*array[:,j,1]\n",
    "            corrArray[:,j,2] = _Ab + _Bb*array[:,j,2]\n",
    "    \n",
    "        g.setArray(corrArray)\n",
    "        g.readMultilinearRegressionFile(calFileWithLatCorr)\n",
    "        imgcorr = g.convertToDose(rect_imgs[i], rect_imgsCtrl[i])\n",
    "\n",
    "        imgs_corr[:,:,i] = registerImgs(refImg_noCorr, imgcorr)\n",
    "    \n",
    "except ValueError as err:\n",
    "    print('Erreur: '+err)\n",
    "\n",
    "    \n",
    "    \n",
    "# Visualization:    \n",
    "if visu:\n",
    "    img1 = refImg_corr\n",
    "    img2 = refImg_noCorr#imgs[:,:,regImgNbToDisp]\n",
    "    imgsProfile = imgs_corr\n",
    "    \n",
    "    # Img 1:\n",
    "    p1 = figure(plot_width=dimViewer, plot_height=int(dimViewer*img1.shape[0]/img1.shape[1]), \n",
    "                title='Reference image', toolbar_location=\"above\")\n",
    "    p1.image(image=[img1], x=0, y=0, dw=img1.shape[1], dh=img1.shape[0], palette=\"Plasma256\")\n",
    "    p1.line((col, col), (0, img1.shape[0]), line_alpha=0.7, line_color=\"white\")\n",
    "    p1.line((0, img1.shape[1]), (line, line), line_alpha=0.7, line_color=\"white\")\n",
    "\n",
    "\n",
    "    # Img 2\n",
    "    p2 = figure(plot_width=dimViewer, plot_height=int(dimViewer*img2.shape[0]/img2.shape[1]), \n",
    "               title='Registered image', toolbar_location=\"above\")\n",
    "    p2.image(image=[img2], x=0, y=0, dw=img2.shape[1], dh=img2.shape[0], palette=\"Plasma256\")\n",
    "    p2.line((col, col), (0, img2.shape[0]), line_alpha=0.7, line_color=\"white\")\n",
    "    p2.line((0, img2.shape[1]), (line, line), line_alpha=0.7, line_color=\"white\")\n",
    "\n",
    "\n",
    "    # Horizontal profile:\n",
    "    maxx = np.amax(img1[line,:])\n",
    "    if np.amax(img2[line,:])>maxx: maxx = np.amax(img2[line,:])\n",
    "        \n",
    "    p3 = figure(plot_width=dimViewer, plot_height=int(dimViewer*2/3), title=\"x profile\", \n",
    "                toolbar_location=\"above\", y_range=(0, int(1.05*maxx)))\n",
    "    x3 = np.arange(0, len(img1[line,:]), 1)\n",
    "    x3b = np.arange(0, len(img2[line,:]), 1)\n",
    "    p3.line(x3, img1[line,:], line_width=3, line_color='black', legend_label='Reference Image')\n",
    "    for i in range(len(otherImgNames)):\n",
    "        p3.line(x3, imgsProfile[line,:,i], line_width=1, line_color=colors[i])#, legend_label='pos no'+ str(i))\n",
    "    \n",
    "\n",
    "    # Vertical profile:\n",
    "    p4 = figure(plot_width=dimViewer, plot_height=int(dimViewer*2/3), title=\"y profile\", toolbar_location=\"above\")\n",
    "    x4 = np.arange(0, len(img1[:,col]), 1)\n",
    "    x4b = np.arange(0, len(img2[:,col]), 1)\n",
    "    p4.line(x4, img1[:, col], line_width=3, line_color='black', legend_label='Reference Image')\n",
    "    for i in range(len(otherImgNames)):\n",
    "        p4.line(x4, imgsProfile[:,col,i], line_width=2, line_color=colors[i])#, legend_label='pos no'+ str(i))\n",
    "\n",
    "    grid = gridplot([[p1, p2], [p3, p4]])\n",
    "\n",
    "\n",
    "    show(grid)\n",
    "    \n",
    "print(\"  >>> mULTIPLE iMAGE tEST dONE !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATERAL CORRECTION & CALIBRATION CURVES (R/B method):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# READING CALIBRATION IMAGE & CORRECTS IT:\n",
    "\n",
    "m_path = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/scan 24h/'\n",
    "m_firstNb = 1\n",
    "m_nbOfFiles = 1\n",
    "m_filesName = \"etalonnage_24h_000\"\n",
    "m_fileExtension = \".tif\"\n",
    "\n",
    "m_dimViewer = 600\n",
    "\n",
    "m_dose = [0, 25, 50, 100, 200, 300, 400, 500, 600, 800]\n",
    "\n",
    "rectList = []\n",
    "rectList.append([120,70,200,90])\n",
    "rectList.append([120,100,200,105])\n",
    "rectList.append([120,130,200,150])\n",
    "rectList.append([120,160,200,180])\n",
    "rectList.append([120,190,200,210])\n",
    "rectList.append([120,220,200,240])\n",
    "rectList.append([120,250,200,270])\n",
    "rectList.append([120,280,200,300])\n",
    "rectList.append([120,311,200,331])\n",
    "rectList.append([120,342,200,362])\n",
    "\n",
    "visu = True\n",
    "\n",
    "\n",
    "\n",
    "# Reads the images and computes the mean image:\n",
    "medianImg = medianImage(m_path, m_filesName, m_firstNb, m_fileExtension, m_nbOfFiles)\n",
    "medianImg = subSampleRGBArray(medianImg, m_subfactor)\n",
    "\n",
    "# correcting lateral response\n",
    "corrImg = np.zeros(medianImg.shape)\n",
    "for i in range(medianImg.shape[1]):\n",
    "    posx = i*pixsize  # peut être faire plus précis ensuite..\n",
    "    if posx<np.amin(m_posArr):\n",
    "        posx = np.amin(m_posArr)\n",
    "    elif posx>np.amax(m_posArr):\n",
    "        posx = np.amax(m_posArr)\n",
    "        \n",
    "    _Ar = fAr_lin(posx)\n",
    "    _Ag = fAg_lin(posx)\n",
    "    _Ab = fAb_lin(posx)\n",
    "    _Br = fBr_lin(posx)\n",
    "    _Bg = fBg_lin(posx)\n",
    "    _Bb = fBb_lin(posx)\n",
    "    corrImg[:,i,0] = _Ar + _Br*medianImg[:,i,0]\n",
    "    corrImg[:,i,1] = _Ag + _Bg*medianImg[:,i,1]\n",
    "    corrImg[:,i,2] = _Ab + _Bb*medianImg[:,i,2]\n",
    "\n",
    "\n",
    "# Calculates mean RGB values\n",
    "rValues = []\n",
    "gValues = []\n",
    "bValues = []\n",
    "rCorr = []\n",
    "gCorr = []\n",
    "bCorr = []\n",
    "for i in range(len(rectList)):\n",
    "    rValues.append(np.mean(medianImg[rectList[i][1]:rectList[i][3],\n",
    "                         rectList[i][0]:rectList[i][2], 0]))\n",
    "    gValues.append(np.mean(medianImg[rectList[i][1]:rectList[i][3],\n",
    "                         rectList[i][0]:rectList[i][2], 1]))\n",
    "    bValues.append(np.mean(medianImg[rectList[i][1]:rectList[i][3],\n",
    "                         rectList[i][0]:rectList[i][2], 2]))\n",
    "    rCorr.append(np.mean(corrImg[rectList[i][1]:rectList[i][3],\n",
    "                         rectList[i][0]:rectList[i][2], 0]))\n",
    "    gCorr.append(np.mean(corrImg[rectList[i][1]:rectList[i][3],\n",
    "                         rectList[i][0]:rectList[i][2], 1]))\n",
    "    bCorr.append(np.mean(corrImg[rectList[i][1]:rectList[i][3],\n",
    "                         rectList[i][0]:rectList[i][2], 2]))\n",
    "\n",
    "\n",
    "# Visualization:\n",
    "if visu:\n",
    "    p = figure(plot_width=m_dimViewer, plot_height=int(m_dimViewer*medianImg.shape[0]/medianImg.shape[1]), \n",
    "                   title='Calibration image', toolbar_location=\"above\")\n",
    "    p.image(image=[medianImg[:,:,0]], x=0, y=0, dw=medianImg.shape[1], dh=medianImg.shape[0], palette=\"Greys256\")\n",
    "    for i in range(len(rectList)):\n",
    "        p.rect(x=int(rectList[i][0]+(rectList[i][2]-rectList[i][0])/2), \n",
    "                   y=int(rectList[i][1]+(rectList[i][3]-rectList[i][1])/2), \n",
    "                   width=rectList[i][2]-rectList[i][0],\n",
    "                   height=rectList[i][3]-rectList[i][1], \n",
    "                   fill_alpha=0,\n",
    "                   line_color=\"firebrick\",\n",
    "                   line_alpha=1)\n",
    "\n",
    "    show(p)\n",
    "    \n",
    "\n",
    "print(\"   >>> gREY vALUES cALCULATED !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# R/B CALIBRATION CURVE:\n",
    "\n",
    "visu = False\n",
    "\n",
    "\n",
    "# calculates R/B and dose arrays:\n",
    "rb_values = np.asarray(rValues) / np.asarray(bValues)\n",
    "rb_corr = np.asarray(rCorr) / np.asarray(bCorr)\n",
    "\n",
    "cs = CubicSpline(rb_values[::-1], m_dose[::-1])\n",
    "csCorr = CubicSpline(rb_corr[::-1], m_dose[::-1])\n",
    "\n",
    "# Calibration curve display:\n",
    "if visu:\n",
    "    x = np.linspace(0.7, 1.6, num=91)\n",
    "    p = figure(plot_width=900, plot_height=600, title='RGB values to dose', toolbar_location=\"above\",\n",
    "               x_axis_label='R/B values', y_axis_label='Dose (Gy)')    \n",
    "    \n",
    "    # no corr. points:\n",
    "    p.circle(rb_values, m_dose, size=10, color='darkblue', alpha=0.5, legend_label='no corr.')\n",
    "    p.line(x, cs(x), line_width=2, line_color='darkblue', line_dash='dashed')\n",
    "\n",
    "    # corr. points:\n",
    "    p.circle(rb_corr, m_dose, size=10, color='firebrick', alpha=0.5, legend_label='corr.')\n",
    "    p.line(x, csCorr(x), line_width=2, line_color='firebrick', line_dash='dashed')\n",
    "\n",
    "    show(p)\n",
    "\n",
    "    \n",
    "print(\"   >>> cUBIC sPLINE fIT fOUND !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# SAVE CORRECTED CALIBRATION DATA:\n",
    "\n",
    "#  In the case of a bspline fitting:\n",
    "file1 = open(m_path+\"bSpline_calibWithLateralCorr.txt\",\"w+\")\n",
    "\n",
    "file1.write(\"BSpline fitting data \\n\\n\")\n",
    "file1.write(\"R/B value\\tdose\\n\")\n",
    "for i in range(len(m_dose)):\n",
    "    file1.write(str(rb_corr[i])+'\\t'+str(m_dose[i])+'\\n')\n",
    "\n",
    "file1.close()\n",
    "\n",
    "print('   >>> fILE wRITTEN !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LATERAL CORRECTION & CALIBRATION CURVES (Multilinear method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# READING CALIBRATION IMAGE, CORRECTS IT AND COMPUTES CALIBRATION FACTORS:\n",
    "\n",
    "m_path = 'G:/Commun/PHYSICIENS/Erwann/EBT3/13 - etalonnage lot 02282001/scan 24h/'\n",
    "m_firstNb = 1\n",
    "m_nbOfFiles = 1\n",
    "m_filesName = \"etalonnage_24h_000\"\n",
    "m_fileExtension = \".tif\"\n",
    "\n",
    "m_dimViewer = 600\n",
    "\n",
    "m_dose = [0, 25, 50, 100, 200, 300, 400, 500, 600, 800]\n",
    "\n",
    "rectList = []\n",
    "rectList.append([120,70,200,90])\n",
    "rectList.append([120,100,200,105])\n",
    "rectList.append([120,130,200,150])\n",
    "rectList.append([120,160,200,180])\n",
    "rectList.append([120,190,200,210])\n",
    "rectList.append([120,220,200,240])\n",
    "rectList.append([120,250,200,270])\n",
    "rectList.append([120,280,200,300])\n",
    "rectList.append([120,311,200,331])\n",
    "rectList.append([120,342,200,362])\n",
    "\n",
    "visu = True\n",
    "pixsize = 1\n",
    "\n",
    "\n",
    "# Etalonnage:\n",
    "try:\n",
    "    g = Radiochromic_multilinear(m_path+m_filesName, m_firstNb, m_nbOfFiles)\n",
    "    g.subSampleDataArray(10)\n",
    "    \n",
    "    img = g.getArray()\n",
    "    corrImg = np.zeros(img.shape)\n",
    "    for i in range(img.shape[1]):\n",
    "        posx = i*pixsize  # peut être faire plus précis ensuite..\n",
    "        if posx<np.amin(m_posArr):\n",
    "            posx = np.amin(m_posArr)\n",
    "        elif posx>np.amax(m_posArr):\n",
    "            posx = np.amax(m_posArr)\n",
    "        \n",
    "        _Ar = fAr_lin(posx)\n",
    "        _Ag = fAg_lin(posx)\n",
    "        _Ab = fAb_lin(posx)\n",
    "        _Br = fBr_lin(posx)\n",
    "        _Bg = fBg_lin(posx)\n",
    "        _Bb = fBb_lin(posx)\n",
    "        corrImg[:,i,0] = _Ar + _Br*img[:,i,0]\n",
    "        corrImg[:,i,1] = _Ag + _Bg*img[:,i,1]\n",
    "        corrImg[:,i,2] = _Ab + _Bb*img[:,i,2]\n",
    "\n",
    "    g.setArray(corrImg)\n",
    "    \n",
    "    g.multilinearRegression(m_dose, rectList, dispResults=True)\n",
    "    g.saveMultilinearRegressionFile(m_path+'multiLinearRegressionCoefficients_02282001_lateralCorr.txt', \n",
    "                            batchNb='02282001', dispStatus=visu)\n",
    "    rgbimg = g.getArray()\n",
    "    size = g.getSize()\n",
    "except ValueError as err:\n",
    "    print('Erreur: ' + err)\n",
    "\n",
    "\n",
    "# Visualization:\n",
    "if visu:\n",
    "    p = figure(plot_width=m_dimViewer, plot_height=int(m_dimViewer*rgbimg.shape[0]/rgbimg.shape[1]), \n",
    "                   title='Calibration image', toolbar_location=\"above\")\n",
    "    p.image(image=[rgbimg[:,:,0]], x=0, y=0, dw=rgbimg.shape[1], dh=rgbimg.shape[0], palette=\"Greys256\")\n",
    "    for i in range(len(rectList)):\n",
    "        p.rect(x=int(rectList[i][0]+(rectList[i][2]-rectList[i][0])/2), \n",
    "                   y=int(rectList[i][1]+(rectList[i][3]-rectList[i][1])/2), \n",
    "                   width=rectList[i][2]-rectList[i][0],\n",
    "                   height=rectList[i][3]-rectList[i][1], \n",
    "                   fill_alpha=0,\n",
    "                   line_color=\"firebrick\",\n",
    "                   line_alpha=1)\n",
    "\n",
    "    show(p)\n",
    "    \n",
    "\n",
    "print(\"   >>> mULTILINEAR cALIBRATION fILE wRITTEN !\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
